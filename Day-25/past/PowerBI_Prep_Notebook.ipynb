{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94671a26",
   "metadata": {},
   "source": [
    "# Energy Load Forecasting — Power BI Prep\n",
    "**Purpose:** Clean the smart-meter dataset, compute KPIs, and export tidy CSVs for a Power BI dashboard.\n",
    "\n",
    "**Inputs:** `/mnt/data/transformed_smart_meter_data.csv`\n",
    "\n",
    "**Outputs (saved to `/mnt/data/powerbi_exports`)**\n",
    "- `fact_timeseries.csv` — long table of timestamped load by meter/location\n",
    "- `kpis.csv` — single-row KPIs (loss ratio, average hourly load, peak demand, monthly consumption)\n",
    "- `by_location.csv` — current KPIs by location\n",
    "- `monthly_consumption.csv` — monthly sums per location\n",
    "- `data_dictionary.md` — column descriptions\n",
    "\n",
    "> **Note on Loss Ratio**: If your dataset has supply vs. billed/consumed columns, set the names in the config cell below. Otherwise the loss ratio will be `NaN` and you can fill it from another source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c32595",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== 0. Imports & Config ====\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- File paths ---\n",
    "RAW_PATH = Path(\"smart_meter_data.csv\")    # change if needed\n",
    "OUTDIR = Path(\"\"); OUTDIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Column configuration ---\n",
    "# Attempt to auto-detect common columns; override if needed.\n",
    "TIMESTAMP_COL = None   # e.g., \"timestamp\"\n",
    "LOAD_COL = None        # e.g., \"kWh\" or \"load\"\n",
    "LOCATION_COL = None    # e.g., \"location\"\n",
    "MSN_COL = None         # e.g., \"msn\" (meter serial number)\n",
    "\n",
    "# If you have technical loss inputs, set these:\n",
    "SUPPLY_ENERGY_COL = None   # e.g., \"energy_input_kWh\" (feeder input)\n",
    "BILLED_ENERGY_COL = None   # e.g., \"metered_energy_kWh\" (sum of meters/billed)\n",
    "\n",
    "# Granularity to standardize to (Power BI friendly)\n",
    "RESAMPLE_RULE = \"1H\"   # hourly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff86dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns: ['datetime', 'msn', 'location', 'daily_consumption_load', 'energy_supplied', 'energy_billed']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>msn</th>\n",
       "      <th>location</th>\n",
       "      <th>daily_consumption_load</th>\n",
       "      <th>energy_supplied</th>\n",
       "      <th>energy_billed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 00:00:00</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 00:15:00</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.12</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 00:30:00</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime       msn location  daily_consumption_load  \\\n",
       "0  2021-01-01 00:00:00  ACE43B7D  Chennai                    2.59   \n",
       "1  2021-01-01 00:15:00  ACE43B7D  Chennai                    1.78   \n",
       "2  2021-01-01 00:30:00  ACE43B7D  Chennai                    2.59   \n",
       "\n",
       "   energy_supplied  energy_billed  \n",
       "0             2.78           2.57  \n",
       "1             2.12           1.86  \n",
       "2             2.68           2.52  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== 1. Load and inspect ====\n",
    "df = pd.read_csv(RAW_PATH)\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b806c59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected TIMESTAMP_COL: datetime\n",
      "Detected LOAD_COL     : daily_consumption_load\n",
      "Detected LOCATION_COL : location\n",
      "Detected MSN_COL      : msn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== 2. Infer column names if not provided ====\n",
    "def guess(colnames, keys):\n",
    "    cand = [c for c in colnames if any(k in c.lower() for k in keys)]\n",
    "    return cand[0] if cand else None\n",
    "\n",
    "cols = list(df.columns)\n",
    "TIMESTAMP_COL = TIMESTAMP_COL or guess(cols, [\"time\",\"date\",\"timestamp\"])\n",
    "LOAD_COL      = LOAD_COL      or guess(cols, [\"consum\",\"kwh\",\"load\",\"usage\",\"energy\"])\n",
    "LOCATION_COL  = LOCATION_COL  or guess(cols, [\"loc\",\"city\",\"region\",\"site\",\"location\"])\n",
    "MSN_COL       = MSN_COL       or guess(cols, [\"msn\",\"meter\",\"serial\",\"meter_id\",\"id\"])\n",
    "\n",
    "print(\"Detected TIMESTAMP_COL:\", TIMESTAMP_COL)\n",
    "print(\"Detected LOAD_COL     :\", LOAD_COL)\n",
    "print(\"Detected LOCATION_COL :\", LOCATION_COL)\n",
    "print(\"Detected MSN_COL      :\", MSN_COL)\n",
    "\n",
    "assert TIMESTAMP_COL is not None, \"Could not detect timestamp column — set TIMESTAMP_COL\"\n",
    "assert LOAD_COL is not None, \"Could not detect load/consumption column — set LOAD_COL\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c376fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_31284\\4201890951.py:15: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_hourly = df.groupby([pd.Grouper(freq=RESAMPLE_RULE)] + ([LOCATION_COL] if LOCATION_COL else []) + ([MSN_COL] if MSN_COL else [])).sum(numeric_only=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>msn</th>\n",
       "      <th>load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 05:00:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01 05:00:00+05:30</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01 05:00:00+05:30</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>7F6ACD62</td>\n",
       "      <td>4.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp   location       msn  load\n",
       "0 2021-01-01 05:00:00+05:30  Bengaluru  0653DAA9  6.05\n",
       "1 2021-01-01 05:00:00+05:30    Chennai  ACE43B7D  4.37\n",
       "2 2021-01-01 05:00:00+05:30      Delhi  7F6ACD62  4.76"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== 3. Parse timestamps, clean, and standardize to hourly ====\n",
    "ts = pd.to_datetime(df[TIMESTAMP_COL], errors=\"coerce\", utc=True).dropna()\n",
    "df = df.loc[ts.index].copy()\n",
    "df[\"timestamp\"] = ts.dt.tz_convert(\"Asia/Kolkata\")  # localize to IST; adjust if needed\n",
    "df = df.sort_values(\"timestamp\")\n",
    "\n",
    "# Keep relevant columns\n",
    "keep = [\"timestamp\", LOAD_COL]\n",
    "if LOCATION_COL and LOCATION_COL in df.columns: keep.append(LOCATION_COL)\n",
    "if MSN_COL and MSN_COL in df.columns: keep.append(MSN_COL)\n",
    "df = df[keep].rename(columns={LOAD_COL:\"load\"}).copy()\n",
    "\n",
    "# If there are multiple readings per hour, aggregate to sum (or mean for power)\n",
    "df = df.set_index(\"timestamp\")\n",
    "df_hourly = df.groupby([pd.Grouper(freq=RESAMPLE_RULE)] + ([LOCATION_COL] if LOCATION_COL else []) + ([MSN_COL] if MSN_COL else [])).sum(numeric_only=True)\n",
    "df_hourly[\"load\"] = df_hourly[\"load\"].interpolate(limit_direction=\"both\")\n",
    "df_hourly = df_hourly.reset_index()\n",
    "\n",
    "df_hourly.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da7328c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_31284\\2064226066.py:9: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df_hourly[\"month\"] = df_hourly[\"timestamp\"].dt.to_period(\"M\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_ratio</th>\n",
       "      <th>average_hourly_load</th>\n",
       "      <th>peak_demand</th>\n",
       "      <th>monthly_consumption</th>\n",
       "      <th>latest_full_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10.170702</td>\n",
       "      <td>18.74</td>\n",
       "      <td>252.61</td>\n",
       "      <td>2024-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_ratio  average_hourly_load  peak_demand  monthly_consumption  \\\n",
       "0         NaN            10.170702        18.74               252.61   \n",
       "\n",
       "  latest_full_month  \n",
       "0           2024-01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== 4. Compute KPIs ====\n",
    "# Average Hourly Load across dataset\n",
    "avg_hourly_load = df_hourly[\"load\"].mean()\n",
    "\n",
    "# Peak Demand (max hourly load)\n",
    "peak_demand = df_hourly[\"load\"].max()\n",
    "\n",
    "# Monthly Consumption (sum over the latest full calendar month across all meters)\n",
    "df_hourly[\"month\"] = df_hourly[\"timestamp\"].dt.to_period(\"M\")\n",
    "latest_full_month = df_hourly[\"month\"].max()\n",
    "monthly_consumption = df_hourly.loc[df_hourly[\"month\"] == latest_full_month, \"load\"].sum()\n",
    "\n",
    "# Loss Ratio — needs supply vs billed columns; compute if available in raw df at original granularity.\n",
    "if (SUPPLY_ENERGY_COL and SUPPLY_ENERGY_COL in df.columns) and (BILLED_ENERGY_COL and BILLED_ENERGY_COL in df.columns):\n",
    "    # Aggregate to month for stability\n",
    "    tmp = df[[SUPPLY_ENERGY_COL, BILLED_ENERGY_COL]].copy()\n",
    "    tmp[\"timestamp\"] = df.index\n",
    "    tmp = tmp.resample(\"1M\").sum(min_count=1)\n",
    "    loss_ratio = float(1.0 - (tmp[BILLED_ENERGY_COL].sum() / max(1e-6, tmp[SUPPLY_ENERGY_COL].sum())))\n",
    "else:\n",
    "    loss_ratio = np.nan  # left blank unless configured\n",
    "\n",
    "kpi_row = {\n",
    "    \"loss_ratio\": loss_ratio,\n",
    "    \"average_hourly_load\": avg_hourly_load,\n",
    "    \"peak_demand\": peak_demand,\n",
    "    \"monthly_consumption\": monthly_consumption,\n",
    "    \"latest_full_month\": str(latest_full_month)\n",
    "}\n",
    "kpis = pd.DataFrame([kpi_row])\n",
    "kpis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fe7d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>average_hourly_load</th>\n",
       "      <th>peak_demand</th>\n",
       "      <th>monthly_consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>10.156018</td>\n",
       "      <td>18.48</td>\n",
       "      <td>47.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chennai</td>\n",
       "      <td>10.176937</td>\n",
       "      <td>18.64</td>\n",
       "      <td>56.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>10.191449</td>\n",
       "      <td>18.49</td>\n",
       "      <td>53.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    location  average_hourly_load  peak_demand  monthly_consumption\n",
       "0  Bengaluru            10.156018        18.48                47.86\n",
       "1    Chennai            10.176937        18.64                56.04\n",
       "2      Delhi            10.191449        18.49                53.09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ==== 5. By-location and monthly tables (for slicers/filters) ====\n",
    "if LOCATION_COL:\n",
    "    # Average Hourly Load by location\n",
    "    avg_by_loc = df_hourly.groupby(LOCATION_COL, as_index=False)[\"load\"].mean().rename(columns={\"load\":\"average_hourly_load\"})\n",
    "    # Peak Demand by location\n",
    "    peak_by_loc = df_hourly.groupby(LOCATION_COL, as_index=False)[\"load\"].max().rename(columns={\"load\":\"peak_demand\"})\n",
    "    # Latest month consumption by location\n",
    "    latest_month = df_hourly[\"month\"].max()\n",
    "    month_mask = df_hourly[\"month\"] == latest_month\n",
    "    mon_by_loc = df_hourly.loc[month_mask].groupby(LOCATION_COL, as_index=False)[\"load\"].sum().rename(columns={\"load\":\"monthly_consumption\"})\n",
    "    by_location = avg_by_loc.merge(peak_by_loc, on=LOCATION_COL, how=\"outer\").merge(mon_by_loc, on=LOCATION_COL, how=\"outer\")\n",
    "else:\n",
    "    by_location = pd.DataFrame()\n",
    "\n",
    "# Monthly sums per location (for charts)\n",
    "if LOCATION_COL:\n",
    "    monthly = (df_hourly\n",
    "               .groupby([LOCATION_COL, \"month\"], as_index=False)\n",
    "               .agg(monthly_consumption=(\"load\",\"sum\")))\n",
    "else:\n",
    "    monthly = (df_hourly\n",
    "               .groupby([\"month\"], as_index=False)\n",
    "               .agg(monthly_consumption=(\"load\",\"sum\")))\n",
    "\n",
    "by_location.head(3) if not by_location.empty else monthly.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6102730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exports written to: .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== 6. Export tidy CSVs for Power BI ====\n",
    "fact = df_hourly[[\"timestamp\",\"load\"] + ([LOCATION_COL] if LOCATION_COL else []) + ([MSN_COL] if MSN_COL else [])].copy()\n",
    "fact.to_csv(OUTDIR/\"fact_timeseries.csv\", index=False)\n",
    "kpis.to_csv(OUTDIR/\"kpis.csv\", index=False)\n",
    "if not by_location.empty:\n",
    "    by_location.to_csv(OUTDIR/\"by_location.csv\", index=False)\n",
    "monthly.to_csv(OUTDIR/\"monthly_consumption.csv\", index=False)\n",
    "\n",
    "dict_txt = '''\n",
    "# Data Dictionary\n",
    "- fact_timeseries.csv\n",
    "  - timestamp (datetime, IST)\n",
    "  - load (numeric; hourly sum or mean depending on your raw data)\n",
    "  - location (text, optional)\n",
    "  - msn (text, optional)\n",
    "\n",
    "- kpis.csv\n",
    "  - loss_ratio (float; requires config)\n",
    "  - average_hourly_load (float)\n",
    "  - peak_demand (float)\n",
    "  - monthly_consumption (float; latest full month)\n",
    "  - latest_full_month (text; YYYY-MM)\n",
    "\n",
    "- by_location.csv\n",
    "  - average_hourly_load, peak_demand, monthly_consumption by location\n",
    "\n",
    "- monthly_consumption.csv\n",
    "  - monthly_consumption by month (and location if available)\n",
    "'''\n",
    "with open(OUTDIR/\"data_dictionary.md\",\"w\") as f:\n",
    "    f.write(dict_txt)\n",
    "\n",
    "print(\"Exports written to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ad8e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "location\n",
       "Chennai      105120\n",
       "Delhi        105120\n",
       "Bengaluru    105120\n",
       "Kolkata      105120\n",
       "Mumbai       105120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('smart_meter_data.csv')\n",
    "df.sample(20)\n",
    "df['location'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a5dfb0",
   "metadata": {},
   "source": [
    "## DAX snippets (copy into Power BI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dad8b96",
   "metadata": {},
   "source": [
    "\n",
    "```DAX\n",
    "-- If you also imported ML outputs:\n",
    "MAE :=\n",
    "AVERAGEX(\n",
    "    'test_predictions',\n",
    "    ABS('test_predictions'[actual] - 'test_predictions'[predicted])\n",
    ")\n",
    "\n",
    "RMSE :=\n",
    "VAR _mse =\n",
    "    AVERAGEX(\n",
    "        'test_predictions',\n",
    "        POWER('test_predictions'[actual] - 'test_predictions'[predicted], 2)\n",
    "    )\n",
    "RETURN SQRT(_mse)\n",
    "\n",
    "Average Hourly Load := AVERAGE('fact_timeseries'[load])\n",
    "Peak Demand := MAX('fact_timeseries'[load])\n",
    "\n",
    "Monthly Consumption :=\n",
    "VAR _lastMonth = EOMONTH(TODAY(), -1)\n",
    "RETURN\n",
    "CALCULATE(\n",
    "    SUM('fact_timeseries'[load]),\n",
    "    DATESINPERIOD('fact_timeseries'[timestamp], _lastMonth, MONTH, 1)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9109359",
   "metadata": {},
   "source": [
    "## Build the Power BI page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca915ea5",
   "metadata": {},
   "source": [
    "\n",
    "1) **Get Data → Text/CSV**: import `fact_timeseries.csv`, `kpis.csv` (and `test_predictions.csv`, `next24h_forecast.csv` if using ML visuals).\n",
    "2) **Data model**: Set `timestamp` to Date/Time. Disable Auto Date/Time if you prefer.\n",
    "3) **Cards**: Create four cards bound to (a) `loss_ratio` (format as percentage), (b) `Average Hourly Load`, (c) `Peak Demand`, (d) `Monthly Consumption`.\n",
    "4) **Trend sparkline**: Area/Line chart with Axis=`timestamp`, Values=`load`. Add a **Relative Date slicer** (Last 30/90 days). Turn off gridlines and legends for a clean tile.\n",
    "5) **Filter table**: Add a Table visual with `location` and `msn` (if present). Use it as a selector.\n",
    "6) **Optional visuals**: \n",
    "   - Column chart of `monthly_consumption` by `month` (and `location` stacked).\n",
    "   - Error charts using `test_predictions.csv` with MAE/RMSE measures.\n",
    "7) **Formatting**: Increase card fonts; align tiles to match your Superset layout; apply a dark theme if desired.\n",
    "8) **Publish**: Save PBIX → Publish to Power BI Service → Configure **Scheduled Refresh** if the CSVs live in OneDrive/SharePoint.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
