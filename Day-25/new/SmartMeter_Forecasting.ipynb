{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293347c2",
   "metadata": {},
   "source": [
    "# Smart Meter — 15‑Minute Load Forecasting, EDA & Power BI Prep\n",
    "This notebook assumes **15‑minute load readings** (`daily_consumption_load`) for 5 meters across 5 locations.\n",
    "It performs:\n",
    "- Cleaning & KPI engineering (Loss Ratio = `1 − billed/supplied`, Technical Loss kWh)\n",
    "- EDA (trends, seasonality) at 15‑min/hourly/daily levels\n",
    "- Per‑location forecasting with **HistGradientBoostingRegressor**\n",
    "- **96‑step (next 24 hours)** recursive forecast at 15‑minute intervals\n",
    "- Exports tidy CSVs for Power BI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f9dffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 0) Imports & Config ===\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Paths (change if needed)\n",
    "CANDIDATES = [\n",
    "    Path('smart_meter_data.csv'),\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATES if p.exists()), None)\n",
    "assert DATA_PATH is not None, 'Place your CSV at /mnt/data/smart_meter_data.csv or /mnt/data/transformed_smart_meter_data.csv'\n",
    "\n",
    "OUTDIR = Path('exports_15min'); OUTDIR.mkdir(exist_ok=True)\n",
    "FIGDIR = OUTDIR / 'figs'; FIGDIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d85b342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 525600 | Date range: 2021-01-01 05:30:00+05:30 → 2024-01-01 05:15:00+05:30\n",
      "Locations: 5 ['Chennai' 'Delhi' 'Mumbai' 'Bengaluru' 'Kolkata']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>msn</th>\n",
       "      <th>location</th>\n",
       "      <th>load_15m</th>\n",
       "      <th>energy_supplied</th>\n",
       "      <th>energy_billed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105120</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>7F6ACD62</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420480</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>3F42A75F</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210240</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315360</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>344684B5</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp       msn   location  load_15m  \\\n",
       "0      2021-01-01 05:30:00+05:30  ACE43B7D    Chennai      2.59   \n",
       "105120 2021-01-01 05:30:00+05:30  7F6ACD62      Delhi      2.96   \n",
       "420480 2021-01-01 05:30:00+05:30  3F42A75F     Mumbai      4.83   \n",
       "210240 2021-01-01 05:30:00+05:30  0653DAA9  Bengaluru      1.55   \n",
       "315360 2021-01-01 05:30:00+05:30  344684B5    Kolkata      2.32   \n",
       "\n",
       "        energy_supplied  energy_billed  \n",
       "0                  2.78           2.57  \n",
       "105120             3.14           2.93  \n",
       "420480             4.82           4.81  \n",
       "210240             1.66           1.53  \n",
       "315360             2.40           2.37  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 1) Load & normalize columns ===\n",
    "raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "def guess(cols, keys):\n",
    "    return next((c for c in cols if any(k in c.lower() for k in keys)), None)\n",
    "\n",
    "col_dt  = guess(raw.columns, ['datetime','timestamp','date','time'])\n",
    "col_msn = guess(raw.columns, ['msn','meter','serial','meter_id','id'])\n",
    "col_loc = guess(raw.columns, ['location','city','site','region'])\n",
    "col_load= guess(raw.columns, ['daily_consumption','consumption','load','kwh','energy_use'])\n",
    "col_sup = guess(raw.columns, ['energy_supplied','supplied','supply_input'])\n",
    "col_bil = guess(raw.columns, ['energy_billed','billed','metered'])\n",
    "\n",
    "assert col_dt and col_msn and col_loc and col_load, 'Missing expected columns; check your CSV headers.'\n",
    "\n",
    "df = raw.rename(columns={\n",
    "    col_dt:'timestamp', col_msn:'msn', col_loc:'location', col_load:'load_15m',\n",
    "    col_sup:'energy_supplied', col_bil:'energy_billed'\n",
    "}).copy()\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce', utc=True).dt.tz_convert('Asia/Kolkata')\n",
    "df = df.dropna(subset=['timestamp']).sort_values('timestamp')\n",
    "for c in ['load_15m','energy_supplied','energy_billed']:\n",
    "    if c in df.columns: df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "# Basic checks\n",
    "print('Rows:', len(df), '| Date range:', df['timestamp'].min(), '→', df['timestamp'].max())\n",
    "print('Locations:', df['location'].nunique(), df['location'].unique())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab976ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_5688\\3812801289.py:12: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  .groupby(['location','msn']).resample('1H')\n",
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_5688\\3812801289.py:13: FutureWarning: DataFrameGroupBy.resample operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .agg(load_1h=('load_15m','sum'),\n",
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_5688\\3812801289.py:22: FutureWarning: DataFrameGroupBy.resample operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .agg(load_1d=('load_15m','sum'),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rows</th>\n",
       "      <th>avg_load_15m</th>\n",
       "      <th>peak_load_15m</th>\n",
       "      <th>total_consumption_kwh</th>\n",
       "      <th>system_loss_ratio</th>\n",
       "      <th>total_technical_loss_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>525600</td>\n",
       "      <td>2.542772</td>\n",
       "      <td>5.23</td>\n",
       "      <td>1336481.08</td>\n",
       "      <td>0.074915</td>\n",
       "      <td>108228.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     rows  avg_load_15m  peak_load_15m  total_consumption_kwh  \\\n",
       "0  525600      2.542772           5.23             1336481.08   \n",
       "\n",
       "   system_loss_ratio  total_technical_loss_kwh  \n",
       "0           0.074915                 108228.68  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 2) KPI engineering ===\n",
    "if 'energy_supplied' in df.columns and 'energy_billed' in df.columns:\n",
    "    denom = df['energy_supplied'].replace(0, np.nan)\n",
    "    df['loss_ratio'] = (1.0 - (df['energy_billed'] / denom)).clip(lower=0).fillna(0.0)\n",
    "    df['technical_loss_kwh'] = (df['energy_supplied'] - df['energy_billed']).clip(lower=0)\n",
    "else:\n",
    "    df['loss_ratio'] = np.nan\n",
    "    df['technical_loss_kwh'] = np.nan\n",
    "\n",
    "# Aggregations for other grains\n",
    "df_hourly = (df.set_index('timestamp')\n",
    "               .groupby(['location','msn']).resample('1H')\n",
    "               .agg(load_1h=('load_15m','sum'),\n",
    "                    energy_supplied=('energy_supplied','sum'),\n",
    "                    energy_billed=('energy_billed','sum'),\n",
    "                    loss_ratio=('loss_ratio','mean'),\n",
    "                    technical_loss_kwh=('technical_loss_kwh','sum'))\n",
    "               .reset_index())\n",
    "\n",
    "df_daily = (df.set_index('timestamp')\n",
    "              .groupby(['location','msn']).resample('1D')\n",
    "              .agg(load_1d=('load_15m','sum'),\n",
    "                   energy_supplied=('energy_supplied','sum'),\n",
    "                   energy_billed=('energy_billed','sum'),\n",
    "                   loss_ratio=('loss_ratio','mean'),\n",
    "                   technical_loss_kwh=('technical_loss_kwh','sum'))\n",
    "              .reset_index())\n",
    "\n",
    "# System KPIs\n",
    "kpis = {\n",
    "    'rows': len(df),\n",
    "    'avg_load_15m': df['load_15m'].mean(),\n",
    "    'peak_load_15m': df['load_15m'].max(),\n",
    "    'total_consumption_kwh': df['load_15m'].sum(),\n",
    "    'system_loss_ratio': float(1 - (df['energy_billed'].sum() / max(1e-6, df['energy_supplied'].sum()))) if 'energy_supplied' in df.columns else np.nan,\n",
    "    'total_technical_loss_kwh': float(df['technical_loss_kwh'].sum()) if 'technical_loss_kwh' in df.columns else np.nan\n",
    "}\n",
    "pd.DataFrame([kpis])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b72d375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved EDA tables and trend figure.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_5688\\627053927.py:16: FutureWarning: A grouping was used that is not in the columns of the DataFrame and so was excluded from the result. This grouping will be included in a future version of pandas. Add the grouping as a column of the DataFrame to silence this warning.\n",
      "  hourly_profile = df_hourly.groupby(['location', df_hourly['timestamp'].dt.hour], as_index=False)['load_1h'].mean()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 3) EDA quick looks ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (a) Overall 15-min load trend (sample last 7 days to keep chart light)\n",
    "last_week = df['timestamp'].max() - pd.Timedelta(days=7)\n",
    "sample = df[df['timestamp'] >= last_week]\n",
    "\n",
    "plt.figure(); \n",
    "for loc, sub in sample.groupby('location'):\n",
    "    plt.plot(sub['timestamp'], sub['load_15m'], label=loc, linewidth=0.8)\n",
    "plt.title('15-min Load — last 7 days by location')\n",
    "plt.xticks(rotation=45); plt.tight_layout(); plt.legend(ncol=3, fontsize=8)\n",
    "plt.savefig(FIGDIR/'trend_15m_last7d.png'); plt.close()\n",
    "\n",
    "# (b) Hour-of-day profile by location\n",
    "hourly_profile = df_hourly.groupby(['location', df_hourly['timestamp'].dt.hour], as_index=False)['load_1h'].mean()\n",
    "hourly_profile.rename(columns={'timestamp':'hour'}, inplace=True)\n",
    "hourly_profile.to_csv(OUTDIR/'hourly_profile_by_location.csv', index=False)\n",
    "\n",
    "# (c) Loss ratio by location (daily mean)\n",
    "loss_by_loc = df_daily.groupby('location', as_index=False)['loss_ratio'].mean()\n",
    "loss_by_loc.to_csv(OUTDIR/'loss_ratio_by_location.csv', index=False)\n",
    "\n",
    "print('Saved EDA tables and trend figure.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf0a47fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>msn</th>\n",
       "      <th>load_15m</th>\n",
       "      <th>minute_of_day</th>\n",
       "      <th>quarter</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>lag_1</th>\n",
       "      <th>lag_2</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_12</th>\n",
       "      <th>lag_16</th>\n",
       "      <th>lag_24</th>\n",
       "      <th>lag_48</th>\n",
       "      <th>lag_96</th>\n",
       "      <th>lag_288</th>\n",
       "      <th>lag_672</th>\n",
       "      <th>roll_96</th>\n",
       "      <th>roll_288</th>\n",
       "      <th>roll_672</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2021-01-08 05:30:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>3.54</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.84</td>\n",
       "      <td>3.43</td>\n",
       "      <td>...</td>\n",
       "      <td>4.36</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.49</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.55</td>\n",
       "      <td>2.338333</td>\n",
       "      <td>2.538958</td>\n",
       "      <td>2.574583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2021-01-08 05:45:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>3.44</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1.34</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.33</td>\n",
       "      <td>4.37</td>\n",
       "      <td>4.50</td>\n",
       "      <td>2.358854</td>\n",
       "      <td>2.544722</td>\n",
       "      <td>2.577545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2021-01-08 06:00:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>2.02</td>\n",
       "      <td>360</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.54</td>\n",
       "      <td>...</td>\n",
       "      <td>2.56</td>\n",
       "      <td>1.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>4.12</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.19</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>2.541493</td>\n",
       "      <td>2.575967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2021-01-08 06:15:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>4.24</td>\n",
       "      <td>375</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.02</td>\n",
       "      <td>3.44</td>\n",
       "      <td>...</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.29</td>\n",
       "      <td>2.57</td>\n",
       "      <td>3.28</td>\n",
       "      <td>4.72</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3.11</td>\n",
       "      <td>2.375938</td>\n",
       "      <td>2.533958</td>\n",
       "      <td>2.576310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2021-01-08 06:30:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>0.59</td>\n",
       "      <td>390</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4.24</td>\n",
       "      <td>2.02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.42</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2.52</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.57</td>\n",
       "      <td>3.93</td>\n",
       "      <td>2.67</td>\n",
       "      <td>2.370937</td>\n",
       "      <td>2.542813</td>\n",
       "      <td>2.577991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timestamp   location       msn  load_15m  minute_of_day  \\\n",
       "672 2021-01-08 05:30:00+05:30  Bengaluru  0653DAA9      3.54            330   \n",
       "673 2021-01-08 05:45:00+05:30  Bengaluru  0653DAA9      3.44            345   \n",
       "674 2021-01-08 06:00:00+05:30  Bengaluru  0653DAA9      2.02            360   \n",
       "675 2021-01-08 06:15:00+05:30  Bengaluru  0653DAA9      4.24            375   \n",
       "676 2021-01-08 06:30:00+05:30  Bengaluru  0653DAA9      0.59            390   \n",
       "\n",
       "     quarter  dayofweek  is_weekend  lag_1  lag_2  ...  lag_12  lag_16  \\\n",
       "672        1          4           0   1.84   3.43  ...    4.36    3.59   \n",
       "673        1          4           0   3.54   1.84  ...    0.73    1.34   \n",
       "674        1          4           0   3.44   3.54  ...    2.56    1.53   \n",
       "675        1          4           0   2.02   3.44  ...    2.24    3.29   \n",
       "676        1          4           0   4.24   2.02  ...    1.42    4.36   \n",
       "\n",
       "     lag_24  lag_48  lag_96  lag_288  lag_672   roll_96  roll_288  roll_672  \n",
       "672    3.49    1.63    1.57     1.88     1.55  2.338333  2.538958  2.574583  \n",
       "673    3.19    3.74    3.33     4.37     4.50  2.358854  2.544722  2.577545  \n",
       "674    3.55    4.12    0.49     4.19     1.79  2.360000  2.541493  2.575967  \n",
       "675    2.57    3.28    4.72     1.69     3.11  2.375938  2.533958  2.576310  \n",
       "676    2.52    4.21    0.57     3.93     2.67  2.370937  2.542813  2.577991  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 4) Feature engineering for 15-min forecasting ===\n",
    "# We build per-location models to avoid leakage across meters.\n",
    "# 15-min steps: 96 per day; 7 days = 672 steps.\n",
    "LAGS = [1,2,3,4,8,12,16,24,48,96,288,672]\n",
    "ROLLS = [96, 288, 672]  # 1d, 3d, 7d\n",
    "\n",
    "def build_features(g):\n",
    "    g = g.sort_values('timestamp').copy()\n",
    "    g['minute_of_day'] = g['timestamp'].dt.hour*60 + g['timestamp'].dt.minute\n",
    "    g['quarter'] = g['timestamp'].dt.quarter\n",
    "    g['dayofweek'] = g['timestamp'].dt.dayofweek\n",
    "    g['is_weekend'] = (g['dayofweek']>=5).astype(int)\n",
    "    for lag in LAGS:\n",
    "        g[f'lag_{lag}'] = g['load_15m'].shift(lag)\n",
    "    for win in ROLLS:\n",
    "        g[f'roll_{win}'] = g['load_15m'].shift(1).rolling(win).mean()\n",
    "    return g\n",
    "\n",
    "# Build features per location\n",
    "feat_frames = []\n",
    "for loc, sub in df[df.columns].groupby('location'):\n",
    "    feat = build_features(sub[['timestamp','location','msn','load_15m']].copy())\n",
    "    feat_frames.append(feat)\n",
    "features = pd.concat(feat_frames, ignore_index=True).dropna()\n",
    "features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dd78f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(    location       MAE      RMSE\n",
       " 2      Delhi  1.029511  1.196916\n",
       " 1    Chennai  1.060541  1.218121\n",
       " 0  Bengaluru  1.039606  1.223343\n",
       " 4     Mumbai  1.071065  1.234117\n",
       " 3    Kolkata  1.093073  1.253353,\n",
       "                   timestamp   location  actual  predicted\n",
       " 0 2023-12-25 05:30:00+05:30  Bengaluru    2.34   2.551508\n",
       " 1 2023-12-25 05:45:00+05:30  Bengaluru    2.11   2.541508\n",
       " 2 2023-12-25 06:00:00+05:30  Bengaluru    3.56   2.541423\n",
       " 3 2023-12-25 06:15:00+05:30  Bengaluru    3.03   2.541508\n",
       " 4 2023-12-25 06:30:00+05:30  Bengaluru    1.40   2.541508)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 5) Train per-location models & evaluate on the most recent 7 days ===\n",
    "models = {}\n",
    "metrics = []\n",
    "predictions = []\n",
    "\n",
    "for loc, sub in features.groupby('location'):\n",
    "    sub = sub.sort_values('timestamp')\n",
    "    cutoff = sub['timestamp'].max() - pd.Timedelta(days=7)\n",
    "    train = sub[sub['timestamp'] <= cutoff]\n",
    "    test  = sub[sub['timestamp'] > cutoff]\n",
    "\n",
    "    X_train = train.drop(columns=['load_15m','timestamp','msn','location'])\n",
    "    y_train = train['load_15m']\n",
    "    X_test  = test.drop(columns=['load_15m','timestamp','msn','location'])\n",
    "    y_test  = test['load_15m']\n",
    "\n",
    "    model = HistGradientBoostingRegressor(max_depth=8, learning_rate=0.05, max_iter=500)\n",
    "    model.fit(X_train, y_train)\n",
    "    yhat = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, yhat))\n",
    "    models[loc] = model\n",
    "    metrics.append({'location': loc, 'MAE': mae, 'RMSE': rmse})\n",
    "\n",
    "    p = pd.DataFrame({'timestamp': test['timestamp'], 'location': loc, 'actual': y_test.values, 'predicted': yhat})\n",
    "    predictions.append(p)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics).sort_values('RMSE')\n",
    "pred_df = pd.concat(predictions, ignore_index=True)\n",
    "metrics_df, pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69de39bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location</th>\n",
       "      <th>forecast_15m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01 05:30:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.546900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-01 05:45:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.541508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-01 06:00:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.541508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-01 06:15:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.546116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-01 06:30:00+05:30</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>2.541508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp   location  forecast_15m\n",
       "0 2024-01-01 05:30:00+05:30  Bengaluru      2.546900\n",
       "1 2024-01-01 05:45:00+05:30  Bengaluru      2.541508\n",
       "2 2024-01-01 06:00:00+05:30  Bengaluru      2.541508\n",
       "3 2024-01-01 06:15:00+05:30  Bengaluru      2.546116\n",
       "4 2024-01-01 06:30:00+05:30  Bengaluru      2.541508"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 6) 96-step (24h) recursive forecast at 15-min intervals ===\n",
    "future_all = []\n",
    "\n",
    "for loc, sub in features.groupby('location'):\n",
    "    model = models[loc]\n",
    "    # Get recent history for that location\n",
    "    hist = df[df['location']==loc].sort_values('timestamp')[-(max(ROLLS)+5):].copy()\n",
    "    last_ts = hist['timestamp'].max()\n",
    "\n",
    "    # Build recursive steps\n",
    "    for step in range(1, 96+1):\n",
    "        ts = last_ts + pd.Timedelta(minutes=15*step)\n",
    "        # create feature row using current history\n",
    "        tmp = hist[['timestamp','load_15m']].copy().set_index('timestamp')\n",
    "        row = {\n",
    "            'minute_of_day': ts.hour*60 + ts.minute,\n",
    "            'quarter': ts.quarter,\n",
    "            'dayofweek': ts.dayofweek,\n",
    "            'is_weekend': int(ts.dayofweek>=5)\n",
    "        }\n",
    "        for lag in LAGS:\n",
    "            row[f'lag_{lag}'] = tmp['load_15m'].iloc[-lag] if len(tmp)>=lag else np.nan\n",
    "        for win in ROLLS:\n",
    "            row[f'roll_{win}'] = tmp['load_15m'].iloc[-win:].mean() if len(tmp)>=win else np.nan\n",
    "\n",
    "        row_df = pd.DataFrame([row])\n",
    "        # align columns to training set\n",
    "        X_cols = models[loc].feature_names_in_\n",
    "        for c in X_cols:\n",
    "            if c not in row_df.columns:\n",
    "                row_df[c] = 0.0\n",
    "        row_df = row_df[X_cols]\n",
    "\n",
    "        yhat = float(model.predict(row_df)[0])\n",
    "        future_all.append({'timestamp': ts, 'location': loc, 'forecast_15m': yhat})\n",
    "        # append to history for next step\n",
    "        hist = pd.concat([hist, pd.DataFrame({'timestamp':[ts],'load_15m':[yhat]})], ignore_index=True)\n",
    "\n",
    "forecast_24h = pd.DataFrame(future_all).sort_values(['location','timestamp'])\n",
    "forecast_24h.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2c8c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All exports written to: exports_15min\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 7) Save artifacts for Power BI ===\n",
    "# Facts at three grains\n",
    "df.to_csv(OUTDIR/'fact_15min.csv', index=False)\n",
    "df_hourly.to_csv(OUTDIR/'fact_hourly.csv', index=False)\n",
    "df_daily.to_csv(OUTDIR/'fact_daily.csv', index=False)\n",
    "\n",
    "# Model outputs\n",
    "metrics_df.to_csv(OUTDIR/'model_metrics_by_location.csv', index=False)\n",
    "pred_df.to_csv(OUTDIR/'test_predictions_15m_by_location.csv', index=False)\n",
    "forecast_24h.to_csv(OUTDIR/'next24h_forecast_15m_by_location.csv', index=False)\n",
    "\n",
    "# EDA helper tables\n",
    "hourly_profile.to_csv(OUTDIR/'hourly_profile_by_location.csv', index=False)\n",
    "loss_by_loc.to_csv(OUTDIR/'loss_ratio_by_location.csv', index=False)\n",
    "\n",
    "print('All exports written to:', OUTDIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
