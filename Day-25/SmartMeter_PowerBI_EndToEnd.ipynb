{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7528208",
   "metadata": {},
   "source": [
    "# Smart Meter Analytics, Forecasting & Power BI Prep\n",
    "This notebook cleans the smart-meter dataset, computes KPIs (including **Loss Ratio**), trains forecasting models per meter/location, exports **Power BI**-ready tables, and builds a **CXO 5-slide PPT**.\n",
    "\n",
    "**Inputs:** `smart_meter_data.csv` or `transformed_smart_meter_data.csv`\n",
    "\n",
    "**Outputs:** written to `/mnt/data/smartmeter_outputs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce83e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 0) Config & imports ===\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import timedelta\n",
    "\n",
    "# File paths (change if needed)\n",
    "CANDIDATES = [\n",
    "    Path(\"smart_meter_data.csv\"),\n",
    "    # Path(\"/mnt/data/transformed_smart_meter_data.csv\")\n",
    "]\n",
    "DATA_PATH = next((p for p in CANDIDATES if p.exists()), None)\n",
    "assert DATA_PATH is not None, \"Place your CSV at /mnt/data/smart_meter_data.csv\"\n",
    "OUTDIR = Path(\"smartmeter_outputs\"); OUTDIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706467b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datetime': 'datetime',\n",
       " 'msn': 'msn',\n",
       " 'location': 'location',\n",
       " 'load': 'daily_consumption_load',\n",
       " 'energy_supplied': 'energy_supplied',\n",
       " 'energy_billed': 'energy_billed'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 1) Load & column mapping ===\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Try to map likely columns\n",
    "def guess(colnames, keys):\n",
    "    cands = [c for c in colnames if any(k in c.lower() for k in keys)]\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "col_dt  = guess(df_raw.columns, [\"datetime\",\"date\",\"time\",\"timestamp\"])\n",
    "col_msn = guess(df_raw.columns, [\"msn\",\"meter\",\"serial\",\"meter_id\",\"id\"])\n",
    "col_loc = guess(df_raw.columns, [\"location\",\"city\",\"site\",\"region\"])\n",
    "col_load= guess(df_raw.columns, [\"daily_consumption\",\"consumption\",\"load\",\"kwh\",\"energy_use\"])\n",
    "col_sup = guess(df_raw.columns, [\"energy_supplied\",\"supplied\",\"supply_input\"])\n",
    "col_bil = guess(df_raw.columns, [\"energy_billed\",\"billed\",\"metered\"])\n",
    "\n",
    "mapping = {\n",
    "    \"datetime\": col_dt,\n",
    "    \"msn\": col_msn,\n",
    "    \"location\": col_loc,\n",
    "    \"load\": col_load,\n",
    "    \"energy_supplied\": col_sup,\n",
    "    \"energy_billed\": col_bil\n",
    "}\n",
    "mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbda3021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RRC\\AppData\\Local\\Temp\\ipykernel_13580\\2557658164.py:32: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  df[\"month\"] = df[\"timestamp\"].dt.to_period(\"M\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>msn</th>\n",
       "      <th>location</th>\n",
       "      <th>daily_consumption_load</th>\n",
       "      <th>energy_supplied</th>\n",
       "      <th>energy_billed</th>\n",
       "      <th>loss_ratio</th>\n",
       "      <th>technical_loss_kwh</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.78</td>\n",
       "      <td>2.57</td>\n",
       "      <td>0.075540</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105120</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>7F6ACD62</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>2.96</td>\n",
       "      <td>3.14</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.066879</td>\n",
       "      <td>0.21</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420480</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>3F42A75F</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>4.83</td>\n",
       "      <td>4.82</td>\n",
       "      <td>4.81</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210240</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.66</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315360</th>\n",
       "      <td>2021-01-01 05:30:00+05:30</td>\n",
       "      <td>344684B5</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2021-01</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       timestamp       msn   location  daily_consumption_load  \\\n",
       "0      2021-01-01 05:30:00+05:30  ACE43B7D    Chennai                    2.59   \n",
       "105120 2021-01-01 05:30:00+05:30  7F6ACD62      Delhi                    2.96   \n",
       "420480 2021-01-01 05:30:00+05:30  3F42A75F     Mumbai                    4.83   \n",
       "210240 2021-01-01 05:30:00+05:30  0653DAA9  Bengaluru                    1.55   \n",
       "315360 2021-01-01 05:30:00+05:30  344684B5    Kolkata                    2.32   \n",
       "\n",
       "        energy_supplied  energy_billed  loss_ratio  technical_loss_kwh  \\\n",
       "0                  2.78           2.57    0.075540                0.21   \n",
       "105120             3.14           2.93    0.066879                0.21   \n",
       "420480             4.82           4.81    0.002075                0.01   \n",
       "210240             1.66           1.53    0.078313                0.13   \n",
       "315360             2.40           2.37    0.012500                0.03   \n",
       "\n",
       "          month         day  \n",
       "0       2021-01  2021-01-01  \n",
       "105120  2021-01  2021-01-01  \n",
       "420480  2021-01  2021-01-01  \n",
       "210240  2021-01  2021-01-01  \n",
       "315360  2021-01  2021-01-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 2) Clean & derive ===\n",
    "df = df_raw.rename(columns={\n",
    "    mapping[\"datetime\"]: \"timestamp\",\n",
    "    mapping[\"msn\"]: \"msn\",\n",
    "    mapping[\"location\"]: \"location\",\n",
    "    mapping[\"load\"]: \"daily_consumption_load\",\n",
    "    mapping[\"energy_supplied\"]: \"energy_supplied\",\n",
    "    mapping[\"energy_billed\"]: \"energy_billed\",\n",
    "}).copy()\n",
    "\n",
    "# Parse time & sort\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\", utc=True).dt.tz_convert(\"Asia/Kolkata\")\n",
    "df = df.dropna(subset=[\"timestamp\"]).sort_values(\"timestamp\")\n",
    "\n",
    "# Basic sanity\n",
    "for c in [\"daily_consumption_load\",\"energy_supplied\",\"energy_billed\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# Compute Loss Ratio per row if possible: 1 - billed/supplied\n",
    "if \"energy_supplied\" in df.columns and \"energy_billed\" in df.columns:\n",
    "    denom = df[\"energy_supplied\"].replace(0, np.nan)\n",
    "    df[\"loss_ratio\"] = 1.0 - (df[\"energy_billed\"] / denom)\n",
    "    df[\"loss_ratio\"] = df[\"loss_ratio\"].clip(lower=0).fillna(0.0)\n",
    "    df[\"technical_loss_kwh\"] = (df[\"energy_supplied\"] - df[\"energy_billed\"]).clip(lower=0)\n",
    "else:\n",
    "    df[\"loss_ratio\"] = np.nan\n",
    "    df[\"technical_loss_kwh\"] = np.nan\n",
    "\n",
    "# Load factor proxy: daily_consumption_load / peak (per meter-month) if we had max demand;\n",
    "# here we approximate by comparing to the max daily load per meter in the month.\n",
    "df[\"month\"] = df[\"timestamp\"].dt.to_period(\"M\")\n",
    "df[\"day\"] = df[\"timestamp\"].dt.date\n",
    "\n",
    "# Ensure we have exactly 5 meters and locations if present\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e22267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msn</th>\n",
       "      <th>location</th>\n",
       "      <th>daily_consumption_load</th>\n",
       "      <th>energy_supplied</th>\n",
       "      <th>energy_billed</th>\n",
       "      <th>technical_loss_kwh</th>\n",
       "      <th>loss_ratio</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>194.54</td>\n",
       "      <td>208.33</td>\n",
       "      <td>194.24</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344684B5</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>187.21</td>\n",
       "      <td>202.14</td>\n",
       "      <td>188.18</td>\n",
       "      <td>13.96</td>\n",
       "      <td>0.071166</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3F42A75F</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>178.77</td>\n",
       "      <td>191.96</td>\n",
       "      <td>178.16</td>\n",
       "      <td>13.80</td>\n",
       "      <td>0.077742</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7F6ACD62</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>198.92</td>\n",
       "      <td>212.91</td>\n",
       "      <td>198.42</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.066070</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>170.64</td>\n",
       "      <td>184.74</td>\n",
       "      <td>171.03</td>\n",
       "      <td>13.71</td>\n",
       "      <td>0.075629</td>\n",
       "      <td>2021-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        msn   location  daily_consumption_load  energy_supplied  \\\n",
       "0  0653DAA9  Bengaluru                  194.54           208.33   \n",
       "1  344684B5    Kolkata                  187.21           202.14   \n",
       "2  3F42A75F     Mumbai                  178.77           191.96   \n",
       "3  7F6ACD62      Delhi                  198.92           212.91   \n",
       "4  ACE43B7D    Chennai                  170.64           184.74   \n",
       "\n",
       "   energy_billed  technical_loss_kwh  loss_ratio  timestamp  \n",
       "0         194.24               14.09    0.066929 2021-01-01  \n",
       "1         188.18               13.96    0.071166 2021-01-01  \n",
       "2         178.16               13.80    0.077742 2021-01-01  \n",
       "3         198.42               14.49    0.066070 2021-01-01  \n",
       "4         171.03               13.71    0.075629 2021-01-01  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 3) Aggregate to daily series per meter/location ===\n",
    "group_cols = [\"day\"]\n",
    "if \"msn\" in df.columns: group_cols.append(\"msn\")\n",
    "if \"location\" in df.columns: group_cols.append(\"location\")\n",
    "\n",
    "daily = (df\n",
    "         .groupby(group_cols, as_index=False)\n",
    "         .agg(daily_consumption_load=(\"daily_consumption_load\",\"sum\"),\n",
    "              energy_supplied=(\"energy_supplied\",\"sum\"),\n",
    "              energy_billed=(\"energy_billed\",\"sum\"),\n",
    "              technical_loss_kwh=(\"technical_loss_kwh\",\"sum\"),\n",
    "              loss_ratio=(\"loss_ratio\",\"mean\"))\n",
    "        )\n",
    "\n",
    "# Reconstruct timestamp at midnight for Power BI compatibility\n",
    "daily[\"timestamp\"] = pd.to_datetime(daily[\"day\"])\n",
    "daily = daily.drop(columns=[\"day\"]).sort_values(\"timestamp\")\n",
    "daily.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417332c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'avg_daily_load': np.float64(243.88340875912405),\n",
       "  'peak_daily_load': np.float64(300.05),\n",
       "  'total_consumption': np.float64(1336481.0799999998),\n",
       "  'system_loss_ratio': np.float64(0.07491478987647215),\n",
       "  'total_technical_loss_kwh': 108228.68000000001},\n",
       "     location  monthly_consumption  avg_loss_ratio\n",
       " 0  Bengaluru                47.86        0.055811\n",
       " 1    Chennai                56.04        0.073358\n",
       " 2      Delhi                53.09        0.086122\n",
       " 3    Kolkata                41.50        0.093180\n",
       " 4     Mumbai                54.12        0.087071)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 4) KPIs & insights ===\n",
    "# System-wide KPIs\n",
    "kpis = {}\n",
    "kpis[\"avg_daily_load\"] = daily[\"daily_consumption_load\"].mean()\n",
    "kpis[\"peak_daily_load\"] = daily[\"daily_consumption_load\"].max()\n",
    "kpis[\"total_consumption\"] = daily[\"daily_consumption_load\"].sum()\n",
    "\n",
    "if \"energy_supplied\" in daily.columns and daily[\"energy_supplied\"].sum() > 0:\n",
    "    kpis[\"system_loss_ratio\"] = 1.0 - (daily[\"energy_billed\"].sum() / daily[\"energy_supplied\"].sum())\n",
    "    kpis[\"total_technical_loss_kwh\"] = float((daily[\"energy_supplied\"] - daily[\"energy_billed\"]).clip(lower=0).sum())\n",
    "else:\n",
    "    kpis[\"system_loss_ratio\"] = np.nan\n",
    "    kpis[\"total_technical_loss_kwh\"] = np.nan\n",
    "\n",
    "# By-location current month consumption & loss\n",
    "if \"location\" in daily.columns:\n",
    "    current_month = daily[\"timestamp\"].dt.to_period(\"M\").max()\n",
    "    by_loc = (daily[daily[\"timestamp\"].dt.to_period(\"M\") == current_month]\n",
    "              .groupby(\"location\", as_index=False)\n",
    "              .agg(monthly_consumption=(\"daily_consumption_load\",\"sum\"),\n",
    "                   avg_loss_ratio=(\"loss_ratio\",\"mean\")))\n",
    "else:\n",
    "    by_loc = pd.DataFrame()\n",
    "\n",
    "kpis, by_loc.head() if not by_loc.empty else \"No location\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee8f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 5) Feature engineering for forecasting ===\n",
    "# We'll forecast daily_consumption_load per meter (or overall if single series).\n",
    "def make_features(frame):\n",
    "    f = frame.copy()\n",
    "    f[\"dayofweek\"] = f[\"timestamp\"].dt.dayofweek\n",
    "    f[\"month\"] = f[\"timestamp\"].dt.month\n",
    "    f[\"is_weekend\"] = (f[\"dayofweek\"] >= 5).astype(int)\n",
    "    # Lags\n",
    "    for lag in [1,2,3,7,14,28]:\n",
    "        f[f\"lag_{lag}\"] = f[\"daily_consumption_load\"].shift(lag)\n",
    "    # Rolling means\n",
    "    f[\"roll_7\"] = f[\"daily_consumption_load\"].shift(1).rolling(7).mean()\n",
    "    f[\"roll_28\"] = f[\"daily_consumption_load\"].shift(1).rolling(28).mean()\n",
    "    return f\n",
    "\n",
    "# Split utility\n",
    "def time_split(f, test_days=14):\n",
    "    f = f.dropna().sort_values(\"timestamp\")\n",
    "    if len(f) <= test_days*2:\n",
    "        split = int(len(f)*0.8)\n",
    "        return f.iloc[:split], f.iloc[split:]\n",
    "    else:\n",
    "        cutoff = f[\"timestamp\"].max() - pd.Timedelta(days=test_days)\n",
    "        return f[f[\"timestamp\"] <= cutoff], f[f[\"timestamp\"] > cutoff]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea6fc09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msn</th>\n",
       "      <th>location</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACE43B7D</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>20.099898</td>\n",
       "      <td>49.981520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3F42A75F</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>23.070274</td>\n",
       "      <td>51.374346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7F6ACD62</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>26.088817</td>\n",
       "      <td>53.007609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0653DAA9</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>24.090117</td>\n",
       "      <td>53.174742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>344684B5</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>25.536636</td>\n",
       "      <td>56.426312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        msn   location        MAE       RMSE\n",
       "4  ACE43B7D    Chennai  20.099898  49.981520\n",
       "2  3F42A75F     Mumbai  23.070274  51.374346\n",
       "3  7F6ACD62      Delhi  26.088817  53.007609\n",
       "0  0653DAA9  Bengaluru  24.090117  53.174742\n",
       "1  344684B5    Kolkata  25.536636  56.426312"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 6) Train per meter/location models & forecast next 14 days ===\n",
    "series_cols = []\n",
    "if \"msn\" in daily.columns: series_cols.append(\"msn\")\n",
    "if \"location\" in daily.columns: series_cols.append(\"location\")\n",
    "if not series_cols:\n",
    "    daily[\"series_id\"] = \"all\"\n",
    "    series_cols = [\"series_id\"]\n",
    "\n",
    "models_summary = []\n",
    "predictions = []\n",
    "forecasts = []\n",
    "\n",
    "for keys, sub in daily.groupby(series_cols):\n",
    "    sub = sub.sort_values(\"timestamp\")\n",
    "    f = make_features(sub)\n",
    "    train, test = time_split(f, test_days=14)\n",
    "\n",
    "    feature_cols = [c for c in f.columns if c not in [\"timestamp\",\"daily_consumption_load\",\"energy_supplied\",\"energy_billed\",\"technical_loss_kwh\",\"loss_ratio\"] + series_cols]\n",
    "    cat_cols = []  # dayofweek/month are numeric; no cats unless we add series id\n",
    "    X_train, y_train = train[feature_cols], train[\"daily_consumption_load\"]\n",
    "    X_test, y_test = test[feature_cols], test[\"daily_consumption_load\"]\n",
    "\n",
    "    model = Pipeline([\n",
    "        (\"scaler\", StandardScaler(with_mean=False)),\n",
    "        (\"rf\", RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1))\n",
    "    ])\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Store test preds\n",
    "    df_pred = pd.DataFrame({\n",
    "        \"timestamp\": test[\"timestamp\"],\n",
    "        \"actual\": y_test.values,\n",
    "        \"predicted\": y_pred\n",
    "    })\n",
    "    for i, col in enumerate(series_cols):\n",
    "        df_pred[col] = sub.iloc[0][col]\n",
    "    predictions.append(df_pred)\n",
    "\n",
    "    # Recursive 14-day forecast\n",
    "    last_date = sub[\"timestamp\"].max()\n",
    "    history = sub[[\"timestamp\",\"daily_consumption_load\"]].copy().set_index(\"timestamp\").sort_index()\n",
    "    fut_rows = []\n",
    "    for h in range(1, 14+1):\n",
    "        t = last_date + pd.Timedelta(days=h)\n",
    "        # build one-row features from history\n",
    "        feat = {\n",
    "            \"dayofweek\": t.dayofweek,\n",
    "            \"month\": t.month,\n",
    "            \"is_weekend\": 1 if t.dayofweek >=5 else 0,\n",
    "            \"lag_1\": history[\"daily_consumption_load\"].iloc[-1] if len(history)>=1 else np.nan,\n",
    "            \"lag_2\": history[\"daily_consumption_load\"].iloc[-2] if len(history)>=2 else np.nan,\n",
    "            \"lag_3\": history[\"daily_consumption_load\"].iloc[-3] if len(history)>=3 else np.nan,\n",
    "            \"lag_7\": history[\"daily_consumption_load\"].iloc[-7] if len(history)>=7 else np.nan,\n",
    "            \"lag_14\": history[\"daily_consumption_load\"].iloc[-14] if len(history)>=14 else np.nan,\n",
    "            \"lag_28\": history[\"daily_consumption_load\"].iloc[-28] if len(history)>=28 else np.nan,\n",
    "            \"roll_7\": history[\"daily_consumption_load\"].iloc[-7:].mean() if len(history)>=7 else np.nan,\n",
    "            \"roll_28\": history[\"daily_consumption_load\"].iloc[-28:].mean() if len(history)>=28 else np.nan,\n",
    "        }\n",
    "        row = pd.DataFrame([feat])\n",
    "        # align columns\n",
    "        for c in feature_cols:\n",
    "            if c not in row.columns: row[c] = 0.0\n",
    "        row = row[feature_cols]\n",
    "        yhat = float(model.predict(row)[0])\n",
    "        fut_rows.append((t, yhat))\n",
    "        history.loc[t] = yhat\n",
    "\n",
    "    df_fc = pd.DataFrame(fut_rows, columns=[\"timestamp\",\"forecast\"])\n",
    "    for i, col in enumerate(series_cols):\n",
    "        df_fc[col] = sub.iloc[0][col]\n",
    "    forecasts.append(df_fc)\n",
    "\n",
    "    models_summary.append({\n",
    "        **({series_cols[i]: keys[i] for i in range(len(series_cols))} if isinstance(keys, tuple) else {series_cols[0]: keys}),\n",
    "        \"MAE\": mae, \"RMSE\": rmse\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(models_summary).sort_values(\"RMSE\")\n",
    "predictions_df = pd.concat(predictions, ignore_index=True)\n",
    "forecasts_df = pd.concat(forecasts, ignore_index=True)\n",
    "\n",
    "summary.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a58f38d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to: smartmeter_outputs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 7) Export Power BI tables ===\n",
    "# Fact table (daily)\n",
    "fact_daily = daily.copy()\n",
    "# Model metrics per series\n",
    "metrics = summary.copy()\n",
    "\n",
    "# Save\n",
    "fact_daily.to_csv(OUTDIR/\"fact_daily.csv\", index=False)\n",
    "metrics.to_csv(OUTDIR/\"model_metrics_by_series.csv\", index=False)\n",
    "predictions_df.to_csv(OUTDIR/\"test_predictions_by_series.csv\", index=False)\n",
    "forecasts_df.to_csv(OUTDIR/\"next14d_forecast_by_series.csv\", index=False)\n",
    "\n",
    "# KPI table (single row)\n",
    "kpis_df = pd.DataFrame([{\n",
    "    \"avg_daily_load\": kpis[\"avg_daily_load\"],\n",
    "    \"peak_daily_load\": kpis[\"peak_daily_load\"],\n",
    "    \"total_consumption\": kpis[\"total_consumption\"],\n",
    "    \"system_loss_ratio\": kpis[\"system_loss_ratio\"],\n",
    "    \"total_technical_loss_kwh\": kpis[\"total_technical_loss_kwh\"]\n",
    "}])\n",
    "kpis_df.to_csv(OUTDIR/\"kpis.csv\", index=False)\n",
    "\n",
    "# By-location table\n",
    "if isinstance(by_loc, pd.DataFrame) and not by_loc.empty:\n",
    "    by_loc.to_csv(OUTDIR/\"kpi_by_location.csv\", index=False)\n",
    "\n",
    "print(\"Exported to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9fe4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === 8) Optional: create charts saved as PNGs for PPT ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Actual vs Predicted (pick one series as example)\n",
    "if not predictions_df.empty:\n",
    "    ex = predictions_df.copy()\n",
    "    # choose first series\n",
    "    keycols = [c for c in [\"msn\",\"location\"] if c in ex.columns]\n",
    "    if keycols:\n",
    "        gb_key = ex[keycols].apply(lambda r: tuple(r), axis=1).iloc[0]\n",
    "        # filter that group\n",
    "        mask = (ex[keycols] == gb_key).all(axis=1)\n",
    "        exs = ex[mask].sort_values(\"timestamp\").tail(30)\n",
    "    else:\n",
    "        exs = ex.sort_values(\"timestamp\").tail(30)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(exs[\"timestamp\"], exs[\"actual\"], label=\"Actual\")\n",
    "    plt.plot(exs[\"timestamp\"], exs[\"predicted\"], label=\"Predicted\")\n",
    "    plt.title(\"Actual vs Predicted (last ~30 days, sample series)\")\n",
    "    plt.xticks(rotation=45); plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.savefig(OUTDIR/\"actual_vs_pred_sample.png\"); plt.close()\n",
    "\n",
    "# Next 14d forecast (aggregate)\n",
    "agg_fc = forecasts_df.groupby(\"timestamp\", as_index=False)[\"forecast\"].sum()\n",
    "plt.figure()\n",
    "plt.plot(agg_fc[\"timestamp\"], agg_fc[\"forecast\"])\n",
    "plt.title(\"Next 14 Days â€” System Forecast (sum of all meters)\")\n",
    "plt.xticks(rotation=45); plt.tight_layout()\n",
    "plt.savefig(OUTDIR/\"next14d_system_forecast.png\"); plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
